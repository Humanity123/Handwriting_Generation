import sys
sys.path.insert(0,  '../utils')

from config import *
import tensorflow as tf
import numpy as np
import data
import pprint

from __init__ import *
from model_cond import *


pp = pprint.PrettyPrinter()

small = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',
		 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
caps = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',
		'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']
digits = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0']
symbols = [' ']

chars = small + caps + digits + symbols
char_dict = dict(zip(chars, range(1, len(chars) + 1)))


def get_1_hot_data(sentence, char_dict):
	''' function to convert sentences into array of 1-hot vectors.

		All the characters present in the char-dict are converted into 1-hot vectors, with length len(char_dict).
		and their value in the char_dict is used as their index in the 1-hot vector. All the characters not present in
		char_dict are mapped to zero vector.

		Args:
				sentence (string): the string of the sentence which needs to be converted to array of 1-hot vectors.
				char_dict (dictionary): the dictionary which contains the index for all the characters which needs to 
						be converted to 1 hot vectors.

		Returns:
				An array of 1-hot vectors with shape (len(sentence), len(char_dict)) corresponds to the vector representation of 
				the sentence.
	'''

	def get_1_hot(char):
		''' converts the char into 1 hot encoding '''
		vector = np.zeros([len(char_dict) + 1])
		if char in char_dict:
			vector[char_dict[char]] = 1
		return vector

	return np.array([get_1_hot(char) for char in sentence])


def train_and_save_model():
	''' function to train and save the model '''

	mean, std = data.get_data_stats(FLAGS.cond_strokes_train_data)

	# Generating datasets for training and validation
	train_input_data, valid_input_data, train_target_data, valid_target_data, train_sentence_data, valid_sentence_data\
		= data.generate_dataset_cond(FLAGS.cond_strokes_train_data, FLAGS.cond_sentence_train_data, FLAGS.cond_seq_len, FLAGS.cond_sen_len)
	print "Data Loaded!"

	pp.pprint(flags.FLAGS.__flags)

	# Normalising data
	# x = (x - mean) / std
	train_input_data, valid_input_data, train_target_data, valid_target_data = \
		([(stroke - mean) / std for stroke in data]
		 for data in (train_input_data, valid_input_data, train_target_data, valid_target_data))

	# Converting sentence to 1-hot vectors
	train_sentence_vector_data = [get_1_hot_data(
		sentence, char_dict) for sentence in train_sentence_data]
	valid_sentence_vector_data = [get_1_hot_data(
		sentence, char_dict) for sentence in valid_sentence_data]

	with tf.Session() as sess:
		model = SynNet(FLAGS, sess,  training=True)
		model.build_model()

		# Restoring model from saved model if present to resume training
		saver = tf.train.Saver(tf.trainable_variables())
		ckpt = tf.train.get_checkpoint_state(FLAGS.cond_saved_model_directory)
		if ckpt:
			saver.restore(sess, ckpt.model_checkpoint_path)
			print ckpt.model_checkpoint_path, "Pre-trained model loaded"

		model.train(train_input_data, train_target_data,
					train_sentence_vector_data, saver)


def sample(text, length=800):
	''' function to generated handwriting from the saved model 

		Args:
				text (string): The text for which the handwriting is to be generated.
				length (int): The length of the stroke sequence to be generated. Defaults to 800
		Returns:
				Stroke data generated by the model
	'''
	mean, std = data.get_data_stats(FLAGS.cond_strokes_train_data)

	# Converting sentence to 1-hot vectors
	sentence_vector = get_1_hot_data(text, char_dict)
	tf.reset_default_graph()

	with tf.Session() as sess:
		FLAGS.cond_sen_len = len(text)
		model = SynNet(FLAGS, sess,  training=False)
		model.build_model()

		# Restoring model from saved models
		saver = tf.train.Saver(tf.trainable_variables())
		ckpt = tf.train.get_checkpoint_state(FLAGS.cond_saved_model_directory)
		if ckpt:
			saver.restore(sess, ckpt.model_checkpoint_path)
			print ckpt.model_checkpoint_path, "Pre-trained model loaded"
		else:
			raise Exception("No Saved Models Found")

		#strokes =  (model.generate(length, sentence_vector) * std) + mean
		strokes = model.generate(length, sentence_vector)
	
	print "Strokes Generated"
	return strokes

if __name__ == '__main__':
	#train_and_save_model()
	plot_stroke(sample("welcome to lyrebird"))
